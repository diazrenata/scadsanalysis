---
title: "Filtering datasets"
author: Renata Diaz
date: "`r Sys.Date()`"
output: 
    github_document:
       df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(drake)
library(dplyr)
library(ggplot2)
library(scadsanalysis)

theme_set(theme_bw())

knitr::opts_chunk$set(fig.width=3, fig.height=2.5, warning = FALSE, message = FALSE) 
```

We filter datasets in two stages. First, **prior to trying to sample from the feasible set**, we remove communities that have a combined S and N too high for us to sample the feasible set. We also create a sub-sample of the FIA dataset, because it has so many communities (~100,000) and so many of them are extremely small (~90,000 with fewer than 10 species). Sampling all 100,000 communities overwhelms our computational pipeline, so we create a subsample of 20,000 communities comprising all communities with more than 10 species (approx. 10,000) and 10,000 randomly selected communities with 3-10 species. Second, **after sampling but before we aggregate results across communities**, we remove communities that are problematic for a number of more nuanced reasons. This includes having only 1 possible SAD (S = 1, N = S, or N = S + 1). We also filter to communities whose sampled feasible sets yield more than 20 unique values for skewness/evenness. We do this because, if there are fewer than 20 unique values in the comparison vector, it's impossible to be in the 5th or 95th percentile. Finally, we remove communities with only 2 species from analyses for skewness, because  `e1071::skewness()` always = 0 if S = 2. 

## Pre-sampling

The only filtering at this stage is removing large communities and subsampling the FIA database. Communities with very large numbers of individuals become computationally intractable. We set the upper limit at 40720, because this is the largest community we were able to sample given the available resources. This upper limit results in the removal of a total of 4 communities, all of them from the Miscellaneous Abundance Database.

The `download_data` function downloads raw data files from https://github.com/weecology/sad-comparison/ (for BBS, Gentry, Mammal Community  Database, and FIA) and figshare http://figshare.com/files/3097079 (for the Miscellaneous Abundance Database). These raw files are stored in `working-data\abund_data` and are not edited. 

To filter, we can re-load the raw data files and go through the filtering process step by step. In the analysis this is accomplished by running dataset-specific filtering scripts and saving new .csvs, which are then loaded using `load_dataset`. We can manually load the datasets and then compare them to what is returned from `load_dataset`.


### Miscellaneous Abundance Database

- Misc. Abund includes datasets reported as relative abundance in addition to count data. We don't want any communities without counts, so we filter out records where abund = 0.


```{r}

misc_abund_raw <- read.csv(here::here("working-data", "abund_data", "misc_abund_spab.csv"))

misc_abund_raw <- misc_abund_raw %>%
  dplyr::rename(site = Site_ID,
                abund = Abundance)

misc_abund_raw <- misc_abund_raw %>%
  mutate(site = as.character(site),
         dat = "misc_abund",
         singletons = F,
         sim = -99,
         source = "observed") %>%
  filter(abund > 0) %>%
  group_by(site) %>%
  arrange(abund) %>%
  mutate(rank = row_number()) %>%
  ungroup()

misc_abund_loaded <- load_dataset("misc_abund")

```

```{r}
any(!(misc_abund_loaded$abund == misc_abund_raw$abund))
any(!(misc_abund_loaded$site == misc_abund_raw$site))

```

Check community sizes:

```{r}

misc_abund_statevars <- get_statevars(misc_abund_raw)

ggplot(misc_abund_statevars, aes(s0, n0)) +
  geom_point() +
  theme_bw() +
  geom_hline(yintercept = 40720, color = "red")

```


Misc abund has `r sum(misc_abund_statevars$n0 > 40720)` communities that get removed. They are all removed because they have high numbers of individuals.

The filtered database is saved as a .csv and can be loaded with `load_dataset`. We can check that it matches the filtering we have done here:

```{r}

misc_abund_sv_filtered <- misc_abund_statevars %>%
  filter(n0 <= 40720)

misc_abund_filtered <- filter(misc_abund_raw, site %in% misc_abund_sv_filtered$site)

misc_abund_short_loaded <- load_dataset("misc_abund_short")

any(!(misc_abund_short_loaded$abund == misc_abund_filtered$abund))
any(!(misc_abund_short_loaded$site == misc_abund_filtered$site))
```


### FIA

- Load raw FIA data
- Add columns to match what we will get from `load_dataset`
- Load from `load_dataset`

```{r}

fia_raw <- read.csv(here::here("working-data", "abund_data", "fia_spab.csv"), stringsAsFactors = F, header = F, skip = 2)

colnames(fia_raw) <- c("site", "year", "species", "abund")

fia_raw <- fia_raw %>%
  mutate(site = as.character(site),
         dat = "fia",
         singletons = F,
         sim = -99,
         source = "observed") %>%
  filter(abund > 0) %>%
  group_by(site) %>%
  arrange(abund) %>%
  mutate(rank = row_number()) %>%
  ungroup()

fia_loaded <- load_dataset("fia")
```


```{r}
any(!(fia_loaded$abund == fia_raw$abund))
any(!(fia_loaded$site == fia_raw$site))

```

Check community sizes:

```{r}

fia_statevars <- get_statevars(fia_raw)

ggplot(fia_statevars, aes(s0, n0)) +
  geom_point() +
  theme_bw() +
  geom_vline(xintercept = c(1.5, 2.5, 9.5), color = "red")

```

FIA has no extremely large datasets; the largest number of individuals is `r max(fia_statevars$n0)`. However, it has `r nrow(fia_statevars)` communities, of which `r sum(fia_statevars$s0 < 10)` have fewer than 10 species. This many communities overwhelms our computational pipeline. We therefore sample all `r sum(fia_statevars$s0 >= 10)` communities with 10 or more species, and a random subsample of 10,000 communities with 3-9 species. We then run these through the pipeline as two separate databases. `fia_short` is the communities with 10 or more species, and `fia_small` is the 10,000 communities with 3-9 species. We re-combine them as "FIA" for aggregate analyses.


```{r}

fia_sv_short <- fia_statevars %>%
    dplyr::filter(s0 >= 10)

fia_short <- fia_raw %>%
  dplyr::filter(site %in% fia_sv_short$site) %>%
  dplyr::mutate(dat = "fia_short")

fia_short_statevars <- get_statevars(fia_short)

ggplot(fia_short_statevars, aes(s0, n0)) +
  geom_point() +
  ggtitle("fia short, >= 10 species") +
  theme_bw()

fia_sv_small <- fia_statevars %>%
  dplyr::filter(s0 >= 3) %>%
  dplyr::filter(s0 <= 9)

  set.seed(1977)
  fia_sv_small <- fia_sv_small[ sample.int(nrow(fia_sv_small), size = 10000, replace = F), ]



fia_small <- fia_raw %>%
  dplyr::filter(site %in% fia_sv_small$site) %>%
  dplyr::mutate(dat = "fia_small")

fia_small_statevars <- get_statevars(fia_small)

ggplot(fia_small_statevars, aes(s0, n0)) +
  geom_point() +
  ggtitle("fia small, 3-9 species")


```

The "short" and "small" datasets are saved as .csvs and can be loaded using `load_dataset`: 

```{r}

fia_small_loaded <- load_dataset("fia_small")

any(!(fia_small_loaded$abund == fia_small$abund))
any(!(fia_small_loaded$site == fia_small$site))

fia_short_loaded <- load_dataset("fia_short")

any(!(fia_short_loaded$abund == fia_short$abund))
any(!(fia_short_loaded$site == fia_short$site))


```


### BBS

- Load raw BBS data
- Add columns to match what we will get from `load_dataset`
- Load from `load_dataset`

```{r}

bbs_raw <- read.csv(here::here("working-data", "abund_data", "bbs_spab.csv"),  stringsAsFactors = F, header = F, skip = 2)

colnames(bbs_raw) <- c("site", "year", "species", "abund")

bbs_raw <- bbs_raw %>%
  mutate(site = as.character(site),
         dat = "bbs",
         singletons = F,
         sim = -99,
         source = "observed") %>%
  group_by(site) %>%
  arrange(abund) %>%
  mutate(rank = row_number()) %>%
  ungroup()

bbs_loaded <- load_dataset("bbs")
```

Compare loaded to raw:

```{r}
any(!(bbs_loaded$abund == bbs_raw$abund))
any(!(bbs_loaded$site == bbs_raw$site))

```


Check community sizes:

```{r}

bbs_statevars <- get_statevars(bbs_raw)

ggplot(bbs_statevars, aes(s0, n0)) +
  geom_point() +
  theme_bw() +
  geom_hline(yintercept = 40720, color = "red")

```

No communities in BBS have more than 40720 individuals, so all are used at this stage. 


### Gentry

- Load raw Gentry data
- Add columns to match what we will get from `load_dataset`
- Load from `load_dataset`

```{r}

gentry_raw <- read.csv(here::here("working-data", "abund_data", "gentry_spab.csv"),  stringsAsFactors = F, header = F, skip = 2)

colnames(gentry_raw) <- c("site", "year", "species", "abund")

gentry_raw <- gentry_raw %>%
  mutate(site = as.character(site),
         dat = "gentry",
         singletons = F,
         sim = -99,
         source = "observed") %>%
  group_by(site) %>%
  arrange(abund) %>%
  mutate(rank = row_number()) %>%
  ungroup()

gentry_loaded <- load_dataset("gentry")
```

Compare loaded to raw:

```{r}
any(!(gentry_loaded$abund == gentry_raw$abund))
any(!(gentry_loaded$site == gentry_raw$site))

```


Check community sizes:

```{r}

gentry_statevars <- get_statevars(gentry_raw)

ggplot(gentry_statevars, aes(s0, n0)) +
  geom_point() +
  theme_bw() +
  geom_hline(yintercept = 40720, color = "red")

```

No communities in Gentry have more than 40720 individuals, so all are used at this stage. 

### Mammal Community Database

- Load raw MCDB data
- Add columns to match what we will get from `load_dataset`
- Load from `load_dataset`

```{r}

mcdb_raw <- read.csv(here::here("working-data", "abund_data", "mcdb_spab.csv"),  stringsAsFactors = F, header = F, skip = 2)

colnames(mcdb_raw) <- c("site", "year", "species", "abund")

mcdb_raw <- mcdb_raw %>%
  mutate(site = as.character(site),
         dat = "mcdb",
         singletons = F,
         sim = -99,
         source = "observed") %>%
  group_by(site) %>%
  arrange(abund) %>%
  mutate(rank = row_number()) %>%
  ungroup()

mcdb_loaded <- load_dataset("mcdb")
```

Compare loaded to raw:

```{r}
any(!(mcdb_loaded$abund == mcdb_raw$abund))
any(!(mcdb_loaded$site == mcdb_raw$site))

```


Check community sizes:

```{r}

mcdb_statevars <- get_statevars(mcdb_raw)

ggplot(mcdb_statevars, aes(s0, n0)) +
  geom_point() +
  theme_bw() +
  geom_hline(yintercept = 40720, color = "red")

```

No high N communities; so all are included at this stage.

## Post-sampling

We will remove additional communities for more substantive reasons. First we can load `all_di` ("all diversity indices"), which is the combined results across all the communities in all the datasets. Every community that was included for sampling is included in all_di. (Additionally, every community has a "singletons" counterpart, which is the same analysis run adjusted for rarefaction. That analysis is discussed elsewhere, and we ignore the rarefaction-adjusted versions here).

```{r}
all_statevars <- bind_rows(bbs_statevars, fia_short_statevars, fia_small_statevars, gentry_statevars, mcdb_statevars, misc_abund_sv_filtered)


all_di <- read.csv(here::here("analysis", "reports", "all_di.csv"), stringsAsFactors = F)

all_di <- all_di %>%
  filter(!singletons) %>%
  mutate(dat = ifelse(grepl(dat, pattern = "fia"), "fia", dat),
         dat = ifelse(dat == "misc_abund_short", "misc_abund", dat)) %>%
  mutate(Dataset = dat,
    Dataset = ifelse(Dataset == "fia", "Forest Inventory and Analysis", Dataset),
        Dataset = ifelse(Dataset == "bbs", "Breeding Bird Survey", Dataset),
        Dataset = ifelse(Dataset == "mcdb", "Mammal Community DB", Dataset),
        Dataset = ifelse(Dataset == "gentry", "Gentry", Dataset),
        Dataset = ifelse(Dataset == "misc_abund", "Miscellaneous Abundance DB", Dataset))

head(all_di)

nrow(all_di) == nrow(all_statevars)
```

We remove communities with only one possible SAD (N = S, N = S + 1, or S = 1).

```{r}

all_di %>%
  group_by_all() %>%
  mutate(only_one_sad = sum(s0 == n0, s0 == 1, n0 == (s0 + 1)) > 0) %>%
  ungroup() %>%
  group_by(dat) %>%
  summarize(total_only_one_sad = sum(only_one_sad),
            total_sites = dplyr::n()) %>%
  ungroup() %>%
  mutate(all_sites_one_sad = sum(total_only_one_sad),
         all_sites = sum(total_sites))

all_di_filtered <- all_di %>%
  filter(s0 != n0,
         s0 != 1,
         n0 != (s0 + 1))

nrow(all_di_filtered)

```

Removing those with only one SAD results in the removal of 258 sites total. 176 from FIA, 56 from MCDB, and 26 from Misc. Abund.


Finally, we will restrict aggregate analyses to sites whose feasible sets have more than 20 unique values for whichever shape metric we're interested in, **and** we will restrict analyses with skewness to sites with >2 species. This results in these final totals:

```{r}

all_di_filtered %>%
  filter(simpson_unique > 20) %>%
  group_by(dat) %>%
  summarize(sites_for_evenness = dplyr::n()) %>%
  ungroup() %>%
  mutate(total_sites_for_evenness = sum(sites_for_evenness))


all_di_filtered %>%
  filter(skew_unique > 20, s0 > 2) %>%
  group_by(dat) %>%
  summarize(sites_for_skewness = dplyr::n()) %>%
  mutate(total_sites_for_skewness = sum(sites_for_skewness))

```
