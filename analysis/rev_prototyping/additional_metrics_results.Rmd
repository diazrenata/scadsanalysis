---
title: "Other metrics"
author: Renata Diaz
date: "`r Sys.Date()`"
output: 
    github_document:
       df_print: kable
       toc: true

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.dim =c(6,6))
library(drake)
library(dplyr)
library(ggplot2)
library(grid)
theme_set(theme_bw())

all_di <- read.csv(here::here("analysis", "rev_prototyping", "all_di.csv")) 


all_di <- all_di %>%
  mutate(log_nparts = log(gmp:::as.double.bigz(nparts)),
         log_nsamples = log(nsamples),
         log_s0 = log(s0),
         log_n0 = log(n0)) %>%
  filter(n0 != s0,
         s0 != 1,
         !singletons,
         n0 != (s0 + 1)) %>%
  mutate(dat = ifelse(grepl(dat, pattern = "fia"), "fia", dat),
         dat = ifelse(dat == "misc_abund_short", "misc_abund", dat)) %>%
  mutate(Dataset = dat,
         Dataset = ifelse(Dataset == "fia", "FIA", Dataset),
         Dataset = ifelse(Dataset == "bbs", "Breeding Bird Survey", Dataset),
         Dataset = ifelse(Dataset == "mcdb", "Mammal Communities", Dataset),
         Dataset = ifelse(Dataset == "gentry", "Gentry", Dataset),
         Dataset = ifelse(Dataset == "misc_abund", "Misc. Abundance", Dataset)) %>%
  filter(nparts > 20) 


```

All of these currently exclude FIA because those are still running.

## Proportion off

Defined as the proportion of individuals allocated to species of different abundances. Most intuitive as a graph - here are two hypothetical SADs for a community with 7 species and 71 individuals:

```{r}

## Set up the cache and config
db <- DBI::dbConnect(RSQLite::SQLite(), here::here("analysis", "drake", "drake-cache-net.sqlite"))
cache <- storr::storr_dbi("datatable", "keystable", db)
cache$del(key = "lock", namespace = "session")
knitr::opts_chunk$set(fig.width=3, fig.height=2.5, warning = FALSE, message = FALSE) 

example_fs <- readd(fs_s_7_n_71, cache = cache) %>%
  filter(sim %in% c(1, 2)) %>%
  mutate(sim = paste0("sim_", sim))

example_fs_wide <- example_fs %>%
  select(sim, abund, rank) %>%
  tidyr::pivot_wider(id_cols = rank, names_from = sim, values_from = abund)

ggplot(example_fs_wide, aes(rank, sim_1)) +
  geom_point() +
  geom_line() +
  geom_point(aes(rank, sim_2), color = "blue") +
  geom_line(aes(rank, sim_2), color = "blue") +
  geom_ribbon(aes(rank, ymin = sim_1, ymax = sim_2), fill = "grey", alpha = .2) +
  ylab("abund")
```

We take the grey area - the area of difference between the two SADs - and divide it by 2 (because every individual allocated to a different species will count twice), and divide that total by the total number of individuals in the community. In principle this metric ranges from 0 to 1, with 0 being no individuals allocated differently and 1 being all individuals allocated differently, although note that neither 0 nor 1 can actually be achieved. 

Here are those calculations:


```{r, echo = T}
(sum(abs(example_fs_wide$sim_1 - example_fs_wide$sim_2)) / 2) / sum(example_fs_wide$sim_1)

fs_mat <- select(example_fs_wide, sim_1, sim_2) %>% t()

scadsanalysis::proportion_off(fs_mat)

```


This is a metric of dissimiliarty defined for *two* focal vectors. We want to know whether the observed SAD is more unlike the elements of its feasible set than the elements of the feasible set are unlike each other. To do this, we calculate the proportion off between the observed SAD and a large number of samples from the feasible set, and take the mean score of all these comparisons. This tells us how different, on average, the observed SAD is from samples. We then repeat this process many times, but instead of the observed SAD we select a random sample from the feasible set as focal sample, compare this focal sample to many other samples, and take the mean. The distribution of these scores can then be compared directly to the score from the observed sample.


```{r}
ggplot(filter(all_di, nparts > 20), aes(mean_po_comparison_percentile)) +
  geom_histogram() +
  facet_wrap(vars(dat, singletons), scales = "free_y")


all_di %>% filter(nparts >20) %>% group_by(singletons, dat) %>% summarize(high_proportion_off = mean(mean_po_comparison_percentile > 95))

```


Because the units for this metric do not depend on S and N, we can also estimate the effect size as the difference in the proportion off between the observed SAD compared to the feasible set and the proportion off for elements of the feasible set compared to each other. 

Looking at those communities where the observed SAD is much more unlike the elements of the feasible set, than the elements of the FS are unlike each other, we can ask how much *more* dissimilar the SAD is than the 95th percentile of unlikeness from the feasible set:

```{r}

all_di %>%
  filter(mean_po_comparison_percentile > 95) %>%
  group_by(singletons, dat) %>%
  summarize(diff_from_95 = mean(mean_po_comparison - mean_po_comparison_95))


ggplot(filter(all_di, mean_po_comparison_percentile > 95), aes( mean_po_comparison - mean_po_comparison_95)) +
  geom_histogram() +
  facet_wrap(vars(dat), scales = "free_y")


```


That is, e.g. for BBS, the significant deviation is that the observed-to-FS dissimilarity is on average .07 higher than the 95th percentile of FS-to-FS dissimilarity. I am not 100% sure that this is the best way to make this comparison....

We can examine how a one-tailed 95% breadth index changes over the size of the feasible set:

```{r}

ggplot(all_di, aes(nparts, mean_po_comparison_95_ratio_1t, color = dat)) +
  geom_point(alpha= .2) +
  scale_x_log10() +
  theme(legend.position = "top")
# 
# 
# ggplot(all_di, aes(nparts, mean_po_comparison_95_ratio_1t, color = dat)) +
#   geom_point(alpha= .8) +
#   scale_x_log10() +
#   xlim(c(0, 30000))+
#   theme(legend.position = "top")
# 
# 
# ggplot(all_di, aes(nparts, mean_po_comparison_95_ratio_1t, color = dat)) +
#   geom_point(alpha= .8) +
#   scale_x_log10() +
#   xlim(c(0, 2000))+
#   theme(legend.position = "top")

```



## Number of singletons

Visualization and analysis of nsingletons has a little more nuance than the others, because there are often relatively few values for nsingletons at all. 80% of sites have fewer than 20 singletons as the 95th percentile, which is just a rough way of saying that a **lot** of these are going to be sensitive to whether you define the percentiles as > or >=. 

In general the strict > percentile will give you an (appropriately) conservative estimate of how many are extraordinarily **high** and the >= will give you an appropriate estimate of how many are unusually **low**. For most metrics it doesn't really matter, writ large, which you use, because ties are rare. For this one, you get large numbers of sites where a lot of values are = to the observed values, and the >= decision will therefore give you a jump of a lot of percentile scores. 

For the "proportions high/low" calculations, we use *the > percentile for high* and *the >= percentile for low*. For visualization, because we are interested in both unusually high and unusually low scores, we can't just pick one or the other. The histogram using >= is reliable at the high end but has a misleading spike at 0, and vice versa. I am making these plots using the *mean*, which doesn't have the misleading spikes at the extremes but does smear things out a little bit. 


```{r, fig.dim = c(5,5)}

nsingletons_results <- all_di %>%
  group_by_all() %>%
  mutate(singletons_percentile_jump = nsingletons_percentile - nsingletons_percentile_excl,
         nsingletons_percentile_mean = sum(nsingletons_percentile, nsingletons_percentile_excl) / 2) %>%
  ungroup() %>%
  mutate(prop_singles_actual = nsingletons / s0,
         sim_prop_singles_95 = nsingletons_95 / s0,
         sim_prop_singles_mean = nsingletons_mean / s0) %>%
  mutate(actual_minus_95_prop = prop_singles_actual - sim_prop_singles_95) %>%
  mutate(high_singles=nsingletons_percentile > 95,
         high_singles_ex = nsingletons_percentile_excl > 95,
         low_singles = nsingletons_percentile < 5,
         low_singles_ex = nsingletons_percentile_excl < 5) %>%
  mutate(singles_desc = ifelse(high_singles_ex, "high", ifelse(low_singles, "low", "int")))

```


BBS, MCDB, and Misc have too many rare species, while Gentry has too few:


```{r}
ggplot(filter(nsingletons_results, nparts > 20), aes(nsingletons_percentile_mean)) +
  geom_histogram(bins = 100) +
  facet_wrap(vars(dat), scales = "free_y", ncol = 1) +
  geom_vline(xintercept = 95)



nsingletons_results  %>% 
  group_by(dat) %>%
  filter(nparts > 20) %>%
  summarize(            prop_nsingletons_high_raw = mean(nsingletons_percentile_excl > 95),
         #   prop_nsingletons_mean_high_raw = mean(nsingletons_percentile_mean_actual > 95),
      #      prop_nsingletons_mean_high_jk = mean(nsingletons_percentile_mean > 95),
            prop_nsingletons_low_raw = mean(nsingletons_percentile  < 5),
            nsites_included = dplyr::n())

```


_Of sites where the nsingletons value is extreme_, we're looking at - for example, in MCDB - an increase of .2 in the proportion of singleton species in the observed vector over the 95th percentile of scores for the proportion of singleton species for the feasible set:

```{r}

nsingletons_results <- nsingletons_results %>%
  mutate(singletons_change = (nsingletons - nsingletons_95) / s0)

ggplot(filter(nsingletons_results, high_singles_ex), aes(singletons_change)) +
  geom_histogram() +
  facet_wrap(vars(dat), scales = "free")

nsingletons_results %>%
  filter(high_singles_ex) %>%
  group_by(dat) %>%
  summarize(mean_singles_change = mean(singletons_change),
            n = dplyr::n())

```


Broken out by N/S, you can see that the low values are concentrated in the Gentry where N/S < 3, and that high values are most common as N/S > 10:

```{r}

ggplot(nsingletons_results, aes(n0/s0, nsingletons_percentile_excl, color = singles_desc)) +
  geom_point(data = filter(nsingletons_results, singles_desc != "int")) +
  geom_point(alpha = .1, color = "grey") +
  facet_wrap(vars(dat), scales = "free") +
  scale_x_log10() +
  geom_vline(xintercept = c(3, 10))



```


For N/S < 3: 

```{r}
nsingletons_results %>%
  filter(n0/s0 < 3) %>%
  group_by(dat, singletons) %>%
  summarize(
            prop_high_singles_ex = mean(high_singles_ex),
            prop_low_singles = mean(low_singles),
            nsites= dplyr::n()) %>%
  ungroup()

```

For N/S  > 10:

```{r}

nsingletons_results %>%
  filter(n0/s0 > 10) %>%
  group_by(dat, singletons) %>%
  summarize(
            prop_high_singles_ex = mean(high_singles_ex),
            prop_low_singles = mean(low_singles),
            nsites= dplyr::n()) %>%
  ungroup()



```


Breadth index - note use of 2 tailed because of interest in low numbers of singletons for Gentry.

I haven't fully groked the breadth index, but I think...

- It declines with increasing size of the feasible set, but not as dramatically as the other indices.
- The Gentry region (low N/S tail on the right) is not remarkable for the size of the FS or the (2-tailed) breadth index, but has an extremely high median propotion of singletons. 

```{r}

ggplot(all_di, aes(nparts, nsingletons_95_ratio_2t, color = dat)) +
  geom_point(alpha = .3) +
  scale_x_log10() 

# 
# ggplot(all_di, aes(s0, n0, color = nsingletons_95_ratio_2t)) +
#   geom_point(alpha = .3) +
#   scale_x_log10() +
#   scale_y_log10() +
#   scale_color_viridis_c()
# 
# 
# ggplot(all_di, aes(n0/s0, nsingletons_95_ratio_2t, color = dat)) +
#   geom_point(alpha = .3) +
#   scale_x_log10()
# 
# 
# ggplot(all_di, aes(n0/s0, nparts, color = dat)) +
#   geom_point(alpha = .3) +
#   scale_x_log10() +
#   scale_y_log10()


ggplot(all_di, aes(s0, n0, color = nsingletons_median / s0)) +
  geom_point(alpha = .3) +
  scale_x_log10() +
  scale_y_log10() +
  scale_color_viridis_c()

# 
# ggplot(all_di, aes(s0, n0, color = nsingletons / s0)) +
#   geom_point(alpha = .3) +
#   scale_x_log10() +
#   scale_y_log10() +
#   scale_color_viridis_c()


```


## Shannon diversity


Most datasets have very low Shannon diversity, except for Gentry:

```{r}

ggplot(filter(all_di, nparts > 20), aes(shannon_percentile)) +
  geom_histogram(bins = 100) +
  facet_wrap(vars(dat), scales = "free_y", ncol = 1) +
  geom_vline(xintercept = 5)


all_di  %>% 
  group_by(dat) %>%
  filter(nparts > 20) %>%
  summarize(
            prop_shannon_high_raw = mean(shannon_percentile > 95),
            prop_shannon_low_raw = mean(shannon_percentile < 5),
            nsites_included = dplyr::n())
```

```{r}

ggplot(all_di, aes(nparts, shannon_95_ratio_2t, color = dat)) +
  geom_point(alpha = .3) +
  scale_x_log10()

ggplot(all_di, aes(nparts, shannon_95_ratio_2t, color = dat)) +
  geom_point(alpha = .3) +
  scale_x_log10() +
  xlim(0, 100000)

```


## 2 tailed breadth indices

```{r}

ggplot(all_di, aes(nparts, shannon_95_ratio_2t, color = dat)) +
  geom_point(alpha = .3) +
  scale_x_log10()

ggplot(all_di, aes(nparts, skew_95_ratio_2t, color = dat)) +
  geom_point(alpha = .3) +
  scale_x_log10()

ggplot(all_di, aes(nparts, simpson_95_ratio_2t, color = dat)) +
  geom_point(alpha = .3) +
  scale_x_log10()

ggplot(all_di, aes(nparts, nsingletons_95_ratio_2t, color = dat)) +
  geom_point(alpha = .3) +
  scale_x_log10()

```
